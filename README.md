# Movies-ETL
In this analysis, a dataset was created by following the Extract, Transform, and Load (ETL) process for Amazon Prime and its movie streaming services. A dataset was created to reflect movie and ratings data so that Amazon can use it to predict upcoming popular movies. After extracting raw data from Wikipedia and Kaggle and transforming it with Python, it was loaded into a SQL (PostGreSQL) database. In addition to going through the ETL process to create the dataset, an automated pipeline was created so that new raw data could be extracted and be easily transformed and loaded into the database. 
Although a function was created to achieve the same results as the original ETL process, the following assumptions should be taken into consideration:
1)	Raw data comes in the same format as the original “Wiki”, “Kaggle”, and “ratings” files. This is mainly regarding that the datasets have the same headers as the original data and are in the same file formats (JSON for the wiki data and CSV for the Kaggle and ratings data).
2)	Data is being loaded into the same database that was originally used with the same password. Otherwise additional arguments may be required if a different database is being used.
3)	Box Office data still only includes the two forms that were addressed in the function for regular expressions (Ex. “$123.4 million” and “123,456,789”). The same applies for Budget data and release date. 
4)	Ratings data is a similar size, otherwise the chunk size for loading data may have to be adjusted.
5)	The inspect, plan, execute process during the transformation phase of the data remains unchanged. Meaning that the changes that were made in the transform phase of the original data hold the same weight as new data and any other issues that may have risen while inspecting the data that were not implemented still hold low impact. 
